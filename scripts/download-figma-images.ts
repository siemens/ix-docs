/*
 * SPDX-FileCopyrightText: 2025 Siemens AG
 *
 * SPDX-License-Identifier: MIT
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
import fs from 'fs';
import axios from 'axios';
import path from 'path';
import { glob } from 'glob';
import { readFile } from 'fs/promises';
import yargs from 'yargs';
import { hideBin } from 'yargs/helpers';
import { config as dotenv } from '@dotenvx/dotenvx';

dotenv({
  override: true,
});

const isFetching = new Set<string>();

type ImageRequest = Map<string, Set<string>>;

const logger = console;

function getLocalFilename(fileName: string, nodeId: string) {
  const localId = decodeURIComponent(nodeId)
    .replace(/:/, '_')
    .replace(/-/, '_');
  const imageUUID = `${fileName}_${localId}`;
  return `${imageUUID}.png`;
}

async function downloadImageResource(
  fileName: string,
  nodeId: string,
  images: Record<string, string>,
  targetFolder: string,
  retry = false
) {
  let id = decodeURIComponent(nodeId).replace(/-/, ':');

  const s3BucketUrl = images[id];

  const imageUUID = `${fileName}_${id.replace(/:/, '_')}`;
  const imageFileName = getLocalFilename(fileName, nodeId);
  const imagePath = path.join(targetFolder, imageFileName);

  if (!isFetching.has(imageUUID)) {
    isFetching.add(imageUUID);
    logger.debug('Download image for filename', fileName, 'node', id);
    try {
      const imageResponse = await axios.get(s3BucketUrl, {
        responseType: 'stream',
      });

      const imageStream = fs.createWriteStream(imagePath);

      imageResponse.data.pipe(imageStream);

      await new Promise<void>((resolve, reject) => {
        imageStream.on('finish', () => resolve());
        imageStream.on('error', reject);
      });

      logger.debug(`Image downloaded to ${imagePath}`);
    } catch (e) {
      logger.error('Error downloading image', e);
      if (retry) {
        logger.error('Abort retry executed second time', e);
        throw Error(
          'Error downloading image. Abort retry executed second time'
        );
      }
      logger.error('Retry downloading image', e);
      await new Promise<void>((resolve) => {
        setTimeout(async () => {
          await downloadImageResource(
            fileName,
            nodeId,
            images,
            targetFolder,
            true
          );
          resolve();
        }, 2000);
      });
    }
  } else {
    logger.debug('Skip download. Image already existing or in fetching phase.');
  }
}

async function fetchFigmaImageApi(
  fileName: string,
  nodeIds: string[],
  fileVersion?: string
): Promise<Record<string, string>> {
  const ids = nodeIds.join(',');

  const url = `https://api.figma.com/v1/images/${fileName}?ids=${ids}${
    fileVersion ? `&version=${fileVersion}` : ''
  }`;
  const response = await fetch(url, {
    headers: {
      'X-FIGMA-TOKEN': process.env.FIGMA_API_TOKEN!,
    },
  });

  logger.debug('Fetch image resource for', url);

  if (response.status !== 200) {
    logger.error(
      `🪲 Oops! Received unexpected status code ${response.status}`,
      fileName,
      'with node ids:',
      ids
    );

    if (response.status === 429) {
      logger.error('🕰️ Retry after 60 seconds');
      return new Promise((resolve) => {
        setTimeout(() => {
          resolve(fetchFigmaImageApi(fileName, nodeIds, fileVersion));
        }, 60 * 1000);
      });
    }
  }

  const data = await response.json();
  return data.images;
}

function getFigmaMeta(link: string): {
  fileName: string;
  nodeId: string;
} {
  const url = new URL(link);
  const urlPath = url.pathname;
  const urlPaths = urlPath.split('/');
  const fileIndex = urlPaths.findIndex((segment) => segment === 'file');
  const designIndex = urlPaths.findIndex((segment) => segment === 'design');
  const branchIndex = urlPaths.findIndex((segment) => segment === 'branch');

  let file = '';

  if (designIndex !== -1 && fileIndex === -1) {
    file = urlPaths[designIndex + 1];
  } else {
    file = urlPaths[fileIndex + 1];
  }

  const fileName = branchIndex !== -1 ? urlPaths[branchIndex + 1] : file;

  const nodeId = url.searchParams.get('node-id')!;
  return {
    fileName,
    nodeId,
  };
}

async function updateFigmaImage(regex: string) {
  const imageRequests: ImageRequest = new Map<string, Set<string>>();

  const markdownPath = path.join(process.cwd(), regex);
  const findings = await glob(markdownPath, {
    ignore: '**/autogenerated/**',
  });

  for (const file of findings) {
    const content = await readFile(file, 'utf-8');
    const figmaImageLinks = content.matchAll(
      /!\[.*\]\((https:\/\/www\.figma\.com\/.*)\)/g
    );
    if (figmaImageLinks) {
      for (const link of figmaImageLinks) {
        const { fileName, nodeId } = getFigmaMeta(link[1]);

        if (imageRequests.has(fileName)) {
          imageRequests.get(fileName)!.add(nodeId);
        } else {
          imageRequests.set(fileName, new Set([nodeId]));
        }
      }
    }
  }

  for (const [fileName, nodeIds] of imageRequests) {
    const images = await fetchFigmaImageApi(fileName, Array.from(nodeIds));
    for (const nodeId of nodeIds) {
      await downloadImageResource(
        fileName,
        nodeId,
        images,
        path.join(process.cwd(), 'static', 'figma')
      );
    }
  }

  console.log('Done');
}

yargs(hideBin(process.argv))
  .command(
    'update [regex]',
    'Update download and replace figma images',
    (yargs) => {
      return yargs.positional('regex', {
        describe: 'The regex to match image links',
        type: 'string',
        default: 'docs/**/*.md?(x)',
      });
    },
    async (argv) => {
      await updateFigmaImage(argv.regex);
    }
  )
  .parse();
